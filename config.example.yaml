# OpenAI Chat Application Configuration
# Copy this file to config.yaml and fill in your API key

openai:
  # Your OpenAI API key (required)
  api_key: "sk-your-api-key-here"
  
  # Model to use for chat completions (optional, default: gpt-3.5-turbo)
  model: "gpt-3.5-turbo"
  
  # Maximum tokens in the response (optional, default: 1000)
  max_tokens: 1000
  
  # Temperature for response randomness 0.0-2.0 (optional, default: 0.7)
  temperature: 0.7
  
  # Base URL for API requests (optional, for proxies or alternative endpoints)
  # base_url: "https://api.openai.com/v1"

# Chat history settings (optional)
history:
  # Directory to store chat sessions (optional, default: ./.gopus/sessions/)
  # sessions_dir: "/path/to/custom/sessions"

# Summarization settings for eternal chat history (optional)
summarization:
  # Enable summarization feature (optional, default: true)
  enabled: true
  
  # Number of recent messages to keep in full detail (optional, default: 20)
  recent_count: 20
  
  # Number of messages to condense before compressing (optional, default: 50)
  condensed_count: 50
  
  # Enable automatic summarization when threshold is exceeded (optional, default: true)
  auto_summarize: true
  
  # Message count threshold to trigger auto-summarization (optional, default: 100)
  auto_threshold: 100
  
  # Custom prompt for condensed summarization (optional)
  # This prompt is used when summarizing messages in the condensed tier.
  # condensed_prompt: |
  #   Summarize the following conversation, preserving:
  #   - Key topics discussed
  #   - Important decisions or conclusions
  #   - Relevant context for future conversations
  #   
  #   Keep the summary concise but informative. Write in third person, describing what the user and assistant discussed.
  
  # Custom prompt for compressed summarization (optional)
  # This prompt is used when creating highly compressed long-term memory summaries.
  # compressed_prompt: |
  #   Create a highly compressed summary of this conversation history.
  #   Include only:
  #   - Main topics covered
  #   - Critical facts or decisions
  #   - Essential context
  #
  #   Be extremely brief - this is long-term memory. Write in third person.

# MCP (Model Context Protocol) settings for external tools (optional)
mcp:
  # Tool confirmation behavior (optional, default: "ask")
  # - "always": Always ask before executing any tool
  # - "never": Execute tools automatically without asking
  # - "ask": Ask based on tool characteristics
  tool_confirmation: "ask"
  
  # Default timeout for MCP requests in seconds (optional, default: 30)
  default_timeout: 30
  
  # Enable debug logging for JSON-RPC messages (optional, default: false)
  # When enabled, all MCP protocol messages will be logged to stderr
  debug: false
  
  # List of MCP servers to connect to (optional)
  servers:
    # Example: Filesystem access server
    # - name: "filesystem"
    #   command: "npx"
    #   args: ["-y", "@modelcontextprotocol/server-filesystem", "/path/to/allowed/dir"]
    #   enabled: true
    
    # Example: GitHub integration server
    # - name: "github"
    #   command: "npx"
    #   args: ["-y", "@modelcontextprotocol/server-github"]
    #   env:
    #     GITHUB_TOKEN: "your-github-token"
    #   enabled: true
    
    # Example: SQLite database server
    # - name: "sqlite"
    #   command: "npx"
    #   args: ["-y", "@modelcontextprotocol/server-sqlite", "/path/to/database.db"]
    #   enabled: true
